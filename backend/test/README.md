# Sistema de Evaluaci√≥n RAG - Nutri-RAG MVP

Sistema completo de evaluaci√≥n para el MVP de Nutri-RAG utilizando **RAGAS**, el framework est√°ndar de la industria para evaluar sistemas RAG.

## üìã Descripci√≥n

Este sistema eval√∫a el rendimiento del RAG en tres dimensiones:

### 1. **M√©tricas de Recuperaci√≥n (Retrieval)**

- **Context Precision**: ¬øLos contextos relevantes est√°n en top positions?
- **Context Recall**: ¬øSe recuperaron todos los contextos necesarios?
- **Precision@k**: Proporci√≥n de docs relevantes recuperados
- **Recall@k**: Cobertura de docs relevantes

### 2. **M√©tricas de Generaci√≥n**

- **Faithfulness** (RAGAS): ¬øLa respuesta est√° basada en el contexto sin inventar?
- **Answer Relevancy** (RAGAS): ¬øLa respuesta es relevante a la pregunta?
- **Answer Correctness** (RAGAS): Precisi√≥n factual vs ground truth
- **BLEU**: Solapamiento de n-gramas (BLEU-1, BLEU-2, BLEU-3, BLEU-4)
- **ROUGE**: Similitud de texto (ROUGE-1, ROUGE-2, ROUGE-L)

### 3. **M√©tricas de Sistema**

- **Coverage**: % de consultas respondidas exitosamente
- **Latency**: Tiempo promedio de respuesta

---

## üöÄ Instalaci√≥n

### 1. Instalar dependencias

Aseg√∫rate de estar en el entorno virtual:

```bash
cd backend
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

Instalar RAGAS y dependencias:

```bash
pip install -r requirements.txt
```

### 2. Configurar OpenAI API Key

Este sistema usa **OpenAI** para las m√©tricas RAGAS (m√°s confiable y r√°pido).

```bash
# Configura tu API key de OpenAI
export OPENAI_API_KEY='tu-api-key-aqui'
```

**Ventajas de usar OpenAI:**

- ‚úÖ Muy r√°pido (2-5 minutos para 5 casos)
- ‚úÖ Resultados confiables y precisos
- ‚úÖ Sin timeouts ni problemas de rendimiento
- ‚úÖ Costo bajo (~$0.10-0.30 USD por 5 casos)

**Obtener API Key:**

1. Ve a https://platform.openai.com/api-keys
2. Crea una cuenta (incluye $5 de cr√©dito gratis)
3. Genera una nueva API key
4. Config√∫rala como variable de entorno

---

## üìä Dataset de Evaluaci√≥n

El archivo `dataset.json` contiene 5 casos de prueba cuidadosamente dise√±ados:

1. **Diabetes Tipo 2**: Alimentos a evitar
2. **Hipertensi√≥n**: Consumo de sodio recomendado
3. **Plan Alimenticio**: Dieta semanal personalizada
4. **Nutrici√≥n Infantil**: Nutrientes esenciales
5. **Prevenci√≥n**: Cambios en estilo de vida

Cada caso incluye:

- `query`: Pregunta de evaluaci√≥n
- `expected_answer`: Respuesta esperada (ground truth)
- `relevant_docs`: IDs de documentos relevantes
- `clinical_data`: Datos del paciente (opcional)
- `category`: Categor√≠a de la pregunta
- `difficulty`: Nivel de dificultad

---

## üîß Uso

### Evaluaci√≥n B√°sica

```bash
cd backend/evaluation
python evaluate_ragas.py
```

### Evaluaci√≥n con Detalles (Verbose)

```bash
python evaluate_ragas.py --verbose
```

---

## üìä Interpretaci√≥n de M√©tricas RAGAS

Todas las m√©tricas RAGAS est√°n en escala **0-1** (0% - 100%):

| Puntaje       | Interpretaci√≥n             |
| ------------- | -------------------------- |
| **‚â• 0.7**     | ‚úÖ Excelente               |
| **0.5 - 0.7** | ‚ö†Ô∏è Bueno (mejoras menores) |
| **< 0.5**     | ‚ùå Necesita mejora         |

### M√©tricas Clave:

**Faithfulness (Fidelidad)** üéØ

- **Qu√© eval√∫a**: ¬øEl sistema inventa informaci√≥n o se basa fielmente en los documentos?
- **Importancia**: CR√çTICA - detecta "alucinaciones"
- **Objetivo**: > 0.8

**Answer Relevancy (Relevancia)** üîç

- **Qu√© eval√∫a**: ¬øLa respuesta responde exactamente lo preguntado?
- **Importancia**: ALTA - evita respuestas gen√©ricas o fuera de tema
- **Objetivo**: > 0.7

**Context Recall (Recall)** üìö

- **Qu√© eval√∫a**: ¬øSe recuper√≥ toda la informaci√≥n necesaria?
- **Importancia**: ALTA - evita respuestas incompletas
- **Objetivo**: > 0.7

**Context Precision (Precisi√≥n)** üéØ

- **Qu√© eval√∫a**: ¬øLos documentos relevantes est√°n en top positions?
- **Importancia**: MEDIA - mejora eficiencia
- **Objetivo**: > 0.6

**Answer Correctness (Precisi√≥n)** ‚úì

- **Qu√© eval√∫a**: ¬øLa respuesta es factualmente correcta?
- **Importancia**: CR√çTICA - informaci√≥n m√©dica debe ser precisa
- **Objetivo**: > 0.8

---

## üõ†Ô∏è Personalizaci√≥n

### Agregar Nuevos Casos de Prueba

Edita `dataset.json` y agrega un nuevo caso:

```json
{
  "id": "test_006",
  "query": "Tu pregunta aqu√≠",
  "expected_answer": "Respuesta esperada",
  "relevant_docs": ["doc_id_1", "doc_id_2"],
  "clinical_data": null,
  "category": "categoria",
  "difficulty": "medium"
}
```

### Modificar M√©tricas Evaluadas

En `evaluate_ragas.py`, l√≠nea ~180, puedes cambiar las m√©tricas:

```python
ragas_results = evaluate(
    ragas_dataset,
    metrics=[
        faithfulness,
        answer_relevancy,
        # Agrega o quita m√©tricas aqu√≠
    ],
)
```

M√©tricas disponibles en RAGAS:

- `faithfulness`
- `answer_relevancy`
- `context_recall`
- `context_precision`
- `answer_correctness`
- `answer_similarity`
- `context_relevancy`

---

## ‚ö†Ô∏è Notas Importantes

### Tiempo de Ejecuci√≥n

- **Evaluaci√≥n del RAG**: 1-3 minutos (5 casos de prueba)
- **Evaluaci√≥n RAGAS con OpenAI**: 2-5 minutos
- **Total**: ~3-8 minutos para evaluaci√≥n completa

### Costos

- **OpenAI API**: ~$0.10-0.30 USD por 5 casos de prueba
- Incluye evaluaci√≥n con GPT-4 mini (muy preciso)
- OpenAI da $5 de cr√©dito gratis al crear cuenta

### M√©tricas Incluidas

**RAGAS (con OpenAI):**

- Faithfulness, Answer Relevancy, Context Recall, Context Precision, Answer Correctness

**Adicionales (librer√≠as Python):**

- Precision@k, Recall@k (recuperaci√≥n)
- BLEU-1, BLEU-2, BLEU-3, BLEU-4 (n-gramas)
- ROUGE-1, ROUGE-2, ROUGE-L (similitud)
- Latency, Coverage

---

## üìö Recursos Adicionales

- [Documentaci√≥n RAGAS](https://docs.ragas.io/)
- [Paper RAGAS](https://arxiv.org/abs/2309.15217)
- [GitHub RAGAS](https://github.com/explodinggradients/ragas)

---

## üêõ Troubleshooting

### Error: "OPENAI_API_KEY no encontrada"

**Soluci√≥n**: Configura la variable de entorno:

```bash
export OPENAI_API_KEY='tu-api-key-aqui'

# O agr√©gala a tu .bashrc/.zshrc para que persista:
echo 'export OPENAI_API_KEY="tu-api-key"' >> ~/.zshrc
```

### Error: "Rate limit exceeded"

**Soluci√≥n**: Has superado el l√≠mite de la API de OpenAI. Espera un momento o verifica tu tier en OpenAI.

### Error: "Module 'ragas' not found"

**Soluci√≥n**: Instala RAGAS:

```bash
pip install ragas
```

### Error: "ChromaDB connection failed"

**Soluci√≥n**: Verifica que la base de datos est√© poblada:

```bash
cd backend/core
python populate_database.py
```

### Evaluaci√≥n muy lenta

**Soluci√≥n**:

- Reduce el n√∫mero de casos de prueba
- Usa menos m√©tricas RAGAS
- Usa modelo local m√°s r√°pido

---

## üìû Soporte

Para preguntas sobre:

- **RAGAS**: [GitHub Issues](https://github.com/explodinggradients/ragas/issues)
- **Este proyecto**: Contacta al equipo de desarrollo

---

_Sistema de evaluaci√≥n desarrollado para Nutri-RAG MVP - 2025_
